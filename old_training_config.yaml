# device
mode: train # train  # train sample
gpu_ids: [3] #[0, 1, 2, 3] # [2, 3] #[ 0, 1, 2, 3 ]  # gpu ids
batch_size: 1   # 1  # batch size each item denotes one story
num_workers: 4  # number of workers
num_cpu_cores: -1  # number of cpu cores
seed: 42 # 0  # random seed
ckpt_dir: /home/houyi/projects/ARLDM/ckpts # checkpoint directory
# run_name: flintstones_ful_02 # proro_1_10      # your_run_name # name for this run
run_name: flintstones_test_01 # proro_1_10 

# task
dataset: flintstones # pororo  # pororo flintstones vistsis vistdii
task: continuation  # continuation visualization

# train
init_lr:  1e-5 # 1e-5  # initial learning rate
warmup_epochs: 1  # warmup epochs
max_epochs: 30 # 50  # max epochs
train_model_file:  #/home/houyi/projects/ARLDM/trained_model # model file for resume, none for train from scratch
freeze_clip: True # False  # whether to freeze clip
freeze_blip: True # False  # whether to freeze blip
freeze_resnet: True # False  # whether to freeze resnet


#  The ddim scheduler with 50 steps provide a 2-3 higher FID score result. 
#  We suggest using ddim-6-250 or pndm-7.5-50 (this is faster and provide a 1-2 higher FID score)
# sample
test_model_file:  /home/houyi/projects/ARLDM/ckpts/flintstones_sub_01/last.ckpt # model file for test
calculate_fid: True  # whether to calculate FID scores
scheduler: ddim  # ddim pndm
guidance_scale: 6  # guidance scale
num_inference_steps: 250  # number of inference steps
sample_output_dir: /home/houyi/projects/ARLDM/samples_output # output directory

pororo:
  hdf5_file:  /home/houyi/projects/ARLDM/processed_subsets/pororo_1_10.h5   #/path/to/pororo.h5
  max_length: 85
  new_tokens: [ "pororo", "loopy", "eddy", "harry", "poby", "tongtong", "crong", "rody", "petty" ]
  clip_embedding_tokens: 49416
  blip_embedding_tokens: 30530

flintstones:
  hdf5_file: /home/houyi/projects/ARLDM/processed_datasets/flintstones.h5 # /home/houyi/projects/ARLDM/processed_subsets/flintstones_8.h5     # /home/houyi/projects/ARLDM/processed_datasets/flintstones.h5
  max_length: 91
  new_tokens: [ "fred", "barney", "wilma", "betty", "pebbles", "dino", "slate" ]
  clip_embedding_tokens: 49412
  blip_embedding_tokens: 30525

vistsis:
  hdf5_file: /path/to/vist.h5
  max_length: 100
  clip_embedding_tokens: 49408
  blip_embedding_tokens: 30524

vistdii:
  hdf5_file: /path/to/vist.h5
  max_length: 65
  clip_embedding_tokens: 49408
  blip_embedding_tokens: 30524

hydra:
  run:
    dir: .
  output_subdir: null
hydra/job_logging: disabled
hydra/hydra_logging: disabled



